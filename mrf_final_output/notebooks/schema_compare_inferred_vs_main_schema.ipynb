{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f8c5a6",
   "metadata": {},
   "source": [
    "# Compare `main_schema.json` vs Spark-Inferred Schema by Group\n",
    "\n",
    "This notebook intentionally **does not use `main_schema.json` for parsing**.\n",
    "It infers schema directly from each group's `*.json.gz` payload and then compares to that group's `main_schema.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f274fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.python_executable: C:\\Users\\ichoi\\Documents\\notitle\\.venv\\Scripts\\python.exe\n",
      "plan_download_directory: D:\\payer_mrf_2\\workspace\n",
      "exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, ArrayType\n",
    "\n",
    "CONFIG_PATH = Path(\"../config.yaml\")\n",
    "with CONFIG_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "plan_download_dir = Path(cfg[\"paths\"][\"plan_download_directory\"])\n",
    "python_executable = cfg.get(\"spark\", {}).get(\"python_executable\")\n",
    "if python_executable:\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = python_executable\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON\"] = python_executable\n",
    "    print(f\"spark.python_executable: {python_executable}\")\n",
    "print(f\"plan_download_directory: {plan_download_dir}\")\n",
    "print(f\"exists: {plan_download_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24df4a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 group folder(s)\n",
      "[group=group_e2a4f730934b] files=26 main_schema_exists=True\n"
     ]
    }
   ],
   "source": [
    "group_dirs = sorted([p for p in plan_download_dir.iterdir() if p.is_dir() and p.name.startswith(\"group_\")])\n",
    "print(f\"Found {len(group_dirs)} group folder(s)\")\n",
    "\n",
    "for g in group_dirs:\n",
    "    files = sorted(g.glob(\"*.json.gz\"))\n",
    "    schema = g / \"main_schema.json\"\n",
    "    print(f\"[group={g.name}] files={len(files)} main_schema_exists={schema.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1e07e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session ready\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "builder = SparkSession.builder.appName(\"SchemaCompare-Inferred-vs-Main\")\n",
    "if python_executable:\n",
    "    builder = builder.config(\"spark.pyspark.python\", python_executable)\n",
    "    builder = builder.config(\"spark.pyspark.driver.python\", python_executable)\n",
    "spark = builder.getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"Spark session ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fefa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_schema(dtype, prefix=\"\"):\n",
    "    \"\"\"Return {path: simpleTypeString} for all fields recursively.\"\"\"\n",
    "    out = {}\n",
    "    if isinstance(dtype, StructType):\n",
    "        for f in dtype.fields:\n",
    "            name = f\"{prefix}.{f.name}\" if prefix else f.name\n",
    "            out.update(flatten_schema(f.dataType, name))\n",
    "        return out\n",
    "    if isinstance(dtype, ArrayType):\n",
    "        out[prefix] = f\"array<{dtype.elementType.simpleString()}>\"\n",
    "        # also flatten element if struct for deeper visibility\n",
    "        if isinstance(dtype.elementType, StructType):\n",
    "            out.update(flatten_schema(dtype.elementType, f\"{prefix}[]\"))\n",
    "        return out\n",
    "    out[prefix] = dtype.simpleString()\n",
    "    return out\n",
    "\n",
    "def infer_schema_from_group(group_dir: Path):\n",
    "    \"\"\"Infer schema directly from JSON text payloads in *.json.gz files.\"\"\"\n",
    "    json_files = sorted(group_dir.glob(\"*.json.gz\"))\n",
    "    if not json_files:\n",
    "        return None\n",
    "\n",
    "    # Infer directly from JSON file paths (multiLine JSON), without using main_schema.\n",
    "    inferred_df = spark.read.option(\"multiLine\", \"true\").json([str(p) for p in json_files])\n",
    "    return inferred_df.schema\n",
    "\n",
    "def load_main_schema(group_dir: Path):\n",
    "    p = group_dir / \"main_schema.json\"\n",
    "    if not p.exists():\n",
    "        return None\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return StructType.fromJson(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56aaca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[group=group_e2a4f730934b] starting comparison\n",
      "[group=group_e2a4f730934b] inferred_fields=23 main_fields=20\n",
      "[group=group_e2a4f730934b] only_in_inferred=7 only_in_main=4 type_mismatch=3\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for g in group_dirs:\n",
    "    print(f\"\\n[group={g.name}] starting comparison\")\n",
    "    inferred = infer_schema_from_group(g)\n",
    "    main_schema = load_main_schema(g)\n",
    "\n",
    "    if inferred is None:\n",
    "        print(f\"[group={g.name}] no json.gz files found\")\n",
    "        rows.append({\"group\": g.name, \"status\": \"no_json_files\"})\n",
    "        continue\n",
    "    if main_schema is None:\n",
    "        print(f\"[group={g.name}] main_schema.json missing\")\n",
    "        rows.append({\"group\": g.name, \"status\": \"missing_main_schema\"})\n",
    "        continue\n",
    "\n",
    "    inf_map = flatten_schema(inferred)\n",
    "    main_map = flatten_schema(main_schema)\n",
    "\n",
    "    inf_keys = set(inf_map.keys())\n",
    "    main_keys = set(main_map.keys())\n",
    "\n",
    "    only_in_inferred = sorted(inf_keys - main_keys)\n",
    "    only_in_main = sorted(main_keys - inf_keys)\n",
    "    common = sorted(inf_keys & main_keys)\n",
    "    type_mismatch = sorted([k for k in common if inf_map[k] != main_map[k]])\n",
    "\n",
    "    print(f\"[group={g.name}] inferred_fields={len(inf_keys)} main_fields={len(main_keys)}\")\n",
    "    print(f\"[group={g.name}] only_in_inferred={len(only_in_inferred)} only_in_main={len(only_in_main)} type_mismatch={len(type_mismatch)}\")\n",
    "\n",
    "    rows.append({\n",
    "        \"group\": g.name,\n",
    "        \"status\": \"ok\",\n",
    "        \"inferred_field_count\": len(inf_keys),\n",
    "        \"main_field_count\": len(main_keys),\n",
    "        \"only_in_inferred_count\": len(only_in_inferred),\n",
    "        \"only_in_main_count\": len(only_in_main),\n",
    "        \"type_mismatch_count\": len(type_mismatch),\n",
    "        \"only_in_inferred_sample\": only_in_inferred[:10],\n",
    "        \"only_in_main_sample\": only_in_main[:10],\n",
    "        \"type_mismatch_sample\": [{\"field\": k, \"inferred\": inf_map[k], \"main\": main_map[k]} for k in type_mismatch[:10]],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc8703d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>status</th>\n",
       "      <th>inferred_field_count</th>\n",
       "      <th>main_field_count</th>\n",
       "      <th>only_in_inferred_count</th>\n",
       "      <th>only_in_main_count</th>\n",
       "      <th>type_mismatch_count</th>\n",
       "      <th>only_in_inferred_sample</th>\n",
       "      <th>only_in_main_sample</th>\n",
       "      <th>type_mismatch_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>group_e2a4f730934b</td>\n",
       "      <td>ok</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[last_updated_on, provider_references, provide...</td>\n",
       "      <td>[last_updated_on.value, reporting_entity_name....</td>\n",
       "      <td>[{'field': 'in_network', 'inferred': 'array&lt;st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                group status  inferred_field_count  main_field_count  \\\n",
       "0  group_e2a4f730934b     ok                    23                20   \n",
       "\n",
       "   only_in_inferred_count  only_in_main_count  type_mismatch_count  \\\n",
       "0                       7                   4                    3   \n",
       "\n",
       "                             only_in_inferred_sample  \\\n",
       "0  [last_updated_on, provider_references, provide...   \n",
       "\n",
       "                                 only_in_main_sample  \\\n",
       "0  [last_updated_on.value, reporting_entity_name....   \n",
       "\n",
       "                                type_mismatch_sample  \n",
       "0  [{'field': 'in_network', 'inferred': 'array<st...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    display(pd.DataFrame(rows))\n",
    "except Exception:\n",
    "    for r in rows:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f0ec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote comparison report: C:\\Users\\ichoi\\Documents\\Unraveled\\mrf_final_output\\notebooks\\schema_compare_results.json\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"schema_compare_results.json\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(rows, f, indent=2)\n",
    "print(f\"Wrote comparison report: {output_path.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
