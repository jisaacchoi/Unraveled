{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e94bd3",
   "metadata": {},
   "source": [
    "# Minimal Gzip + JSON Indexer for Massive MRF Files\n",
    "\n",
    "This notebook provides a **minimal structural indexer** for very large `.json.gz` files (e.g., MRF).\n",
    "\n",
    "## What it does\n",
    "- Streams a `.json.gz` using `indexed_gzip` (supports random access via a gzip index)\n",
    "- Scans for **top-level JSON keys**\n",
    "- Records offsets for **top-level array values** (e.g., `\"in_network\"`, `\"provider_references\"`) without full parsing\n",
    "- Captures **top-level scalar values** (e.g., `\"reporting_entity_name\"`) when present\n",
    "\n",
    "## Outputs\n",
    "- `<file>.index.json`: JSON index with offsets + scalars\n",
    "- `<file>.gzidx`: gzip seek index created/used by `indexed_gzip`\n",
    "\n",
    "## Notes\n",
    "This is **not** a full JSON parser by design. It is intended for the common MRF pattern:\n",
    "- top-level object\n",
    "- large arrays at top-level keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55e0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import indexed_gzip as igzip\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Logging\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Data Structures\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class JsonIndex:\n",
    "    \"\"\"Minimal structural index for a top-level JSON object.\"\"\"\n",
    "    top_level_offsets: Dict[str, int] = field(default_factory=dict)\n",
    "    scalar_values: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def is_whitespace(ch: str) -> bool:\n",
    "    return ch in \" \\t\\n\\r\"\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Core Indexing Logic\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def build_index(\n",
    "    path_gz: Path,\n",
    "    json_index_file: Path,\n",
    "    gzip_index_file: Optional[Path] = None,\n",
    "    spacing: int = 300 * 1024,\n",
    "    chunk_size: int = 64 * 1024,\n",
    "    overlap_size: int = 1024,\n",
    ") -> JsonIndex:\n",
    "    \"\"\"Build a minimal index of top-level JSON keys from a .json.gz file.\n",
    "\n",
    "    Strategy:\n",
    "    - Stream gzip with indexed_gzip\n",
    "    - Scan once\n",
    "    - Track JSON state manually (depth / strings)\n",
    "\n",
    "    Parameters:\n",
    "    - path_gz: input .json.gz\n",
    "    - json_index_file: output index JSON path\n",
    "    - gzip_index_file: optional gzip index path for indexed_gzip\n",
    "    - spacing: gzip index spacing (smaller -> bigger index, faster seeking)\n",
    "    - chunk_size: read size (bytes)\n",
    "    - overlap_size: text overlap retained between chunks for boundary safety\n",
    "    \"\"\"\n",
    "\n",
    "    LOG.info(\"Indexing %s\", path_gz)\n",
    "    if gzip_index_file:\n",
    "        LOG.info(\"Using gzip index: %s\", gzip_index_file)\n",
    "\n",
    "    index = JsonIndex()\n",
    "\n",
    "    with igzip.IndexedGzipFile(\n",
    "        filename=str(path_gz),\n",
    "        index_file=str(gzip_index_file) if gzip_index_file else None,\n",
    "        spacing=spacing,\n",
    "    ) as fh:\n",
    "\n",
    "        buf = \"\"\n",
    "        pos = 0  # decompressed character position (approx) within stream\n",
    "\n",
    "        depth = 0\n",
    "        in_string = False\n",
    "        escape = False\n",
    "        current_key = None\n",
    "\n",
    "        while True:\n",
    "            chunk = fh.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "\n",
    "            text = chunk.decode(\"utf-8\", errors=\"ignore\")\n",
    "            buf += text\n",
    "\n",
    "            i = 0\n",
    "            while i < len(buf):\n",
    "                ch = buf[i]\n",
    "\n",
    "                # String mode\n",
    "                if in_string:\n",
    "                    if escape:\n",
    "                        escape = False\n",
    "                    elif ch == \"\\\\\":\n",
    "                        escape = True\n",
    "                    elif ch == '\"':\n",
    "                        in_string = False\n",
    "                    i += 1\n",
    "                    continue\n",
    "\n",
    "                if ch == '\"':\n",
    "                    # Potential key\n",
    "                    start = i + 1\n",
    "                    end = buf.find('\"', start)\n",
    "                    if end == -1:\n",
    "                        break  # wait for next chunk\n",
    "\n",
    "                    key = buf[start:end]\n",
    "                    i = end + 1\n",
    "\n",
    "                    # Skip whitespace\n",
    "                    while i < len(buf) and is_whitespace(buf[i]):\n",
    "                        i += 1\n",
    "\n",
    "                    # If we're in top-level object depth==1, and next token is ':', treat as key\n",
    "                    if i < len(buf) and buf[i] == \":\" and depth == 1:\n",
    "                        current_key = key\n",
    "                    continue\n",
    "\n",
    "                # Structural depth tracking\n",
    "                if ch == \"{\":\n",
    "                    depth += 1\n",
    "                elif ch == \"}\":\n",
    "                    depth -= 1\n",
    "                elif ch == \"[\":\n",
    "                    # For top-level arrays, record the offset at '['\n",
    "                    if depth == 1 and current_key:\n",
    "                        index.top_level_offsets[current_key] = pos + i\n",
    "                        current_key = None\n",
    "                elif ch not in \",:\" and depth == 1 and current_key:\n",
    "                    # Scalar value (numbers, true/false/null, or quoted strings)\n",
    "                    start = i\n",
    "                    while i < len(buf) and buf[i] not in \",}\":\n",
    "                        i += 1\n",
    "                    value = buf[start:i].strip()\n",
    "                    index.scalar_values[current_key] = value\n",
    "                    current_key = None\n",
    "                    continue\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            # Retain overlap for boundary safety\n",
    "            pos += len(text)\n",
    "            buf = buf[-overlap_size:]\n",
    "\n",
    "    # Persist index\n",
    "    json_index_file.write_text(\n",
    "        json.dumps(\n",
    "            {\"offsets\": index.top_level_offsets, \"scalars\": index.scalar_values},\n",
    "            indent=2,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    LOG.info(\"Index written to %s\", json_index_file)\n",
    "    return index\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Convenience Wrapper\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def build_index_wrapper(input_file: Path, output_dir: Optional[Path] = None) -> JsonIndex:\n",
    "    output_dir = output_dir or input_file.parent\n",
    "\n",
    "    json_index_file = output_dir / f\"{input_file.name}.index.json\"\n",
    "    gzip_index_file = output_dir / f\"{input_file.name}.gzidx\"\n",
    "\n",
    "    return build_index(\n",
    "        path_gz=input_file,\n",
    "        json_index_file=json_index_file,\n",
    "        gzip_index_file=gzip_index_file,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2634cf",
   "metadata": {},
   "source": [
    "## Example usage\n",
    "\n",
    "Update the path below to point to your `.json.gz` MRF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d9d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 14:28:30,152 | INFO | Indexing D:\\2026-01_890_58B0_in-network-rates_58_of_60.json.gz\n",
      "2026-01-26 14:28:30,152 | INFO | Using gzip index: D:\\2026-01_890_58B0_in-network-rates_58_of_60.json.gz.gzidx\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "input_file = Path(\"D://2026-01_890_58B0_in-network-rates_58_of_60.json.gz\")\n",
    "idx = build_index_wrapper(input_file)\n",
    "idx.top_level_offsets, idx.scalar_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094f3a1",
   "metadata": {},
   "source": [
    "## Interpreting output\n",
    "\n",
    "- `offsets`: position (in the decompressed text stream) where the top-level array begins (`[`)\n",
    "- `scalars`: stringified scalar values captured at the top-level\n",
    "\n",
    "If you want offset-based partial extraction helpers (e.g., read the first N items of `in_network`), tell me and I will add them as additional cells."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
